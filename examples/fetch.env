# Environment variables for Beehive fetch command
# Copy this file to .env and customize for your environment
# Load with: source examples/fetch.env

# ============================================================================
# Required Configuration
# ============================================================================

# Path to sources configuration file (TOML format)
# Default: config/config.toml
# The file should contain source definitions (RSS feeds, threat feeds, etc.)
export BEEHIVE_CONFIG="config/config.toml"

# ============================================================================
# Firestore Configuration (Required when not using --dry-run)
# ============================================================================

# Google Cloud Project ID for Firestore storage
# Required when not using --dry-run mode
export BEEHIVE_FIRESTORE_PROJECT_ID="your-gcp-project-id"
# Alternative: export GOOGLE_CLOUD_PROJECT="your-gcp-project-id"

# Firestore Database ID (optional)
# If not specified, uses the default "(default)" database
# Useful when you have multiple Firestore databases in the same project
export BEEHIVE_FIRESTORE_DATABASE_ID="beehive-db"

# ============================================================================
# LLM Configuration (Choose ONE provider)
# ============================================================================

# LLM Provider Selection
# Options: gemini, openai, claude
# Default: gemini
export BEEHIVE_LLM_PROVIDER="gemini"

# --- Option 1: Google Gemini (Default) ---
# Google Cloud project ID for Gemini API
export BEEHIVE_GEMINI_PROJECT="your-gcp-project-id"

# Google Cloud location/region for Gemini
# Default: us-central1
export BEEHIVE_GEMINI_LOCATION="us-central1"

# Gemini model name (optional)
# Example: gemini-1.5-pro, gemini-1.5-flash
# export BEEHIVE_LLM_MODEL="gemini-1.5-pro"

# --- Option 2: OpenAI ---
# Uncomment and set if using OpenAI provider
# export BEEHIVE_LLM_PROVIDER="openai"
# export BEEHIVE_OPENAI_API_KEY="sk-..."
# export BEEHIVE_LLM_MODEL="gpt-4"  # Optional: gpt-4, gpt-3.5-turbo, etc.

# --- Option 3: Claude (Anthropic) ---
# Uncomment and set if using Claude provider
# export BEEHIVE_LLM_PROVIDER="claude"
# export BEEHIVE_CLAUDE_API_KEY="sk-ant-..."
# export BEEHIVE_LLM_MODEL="claude-3-opus-20240229"  # Optional

# ============================================================================
# Optional Configuration
# ============================================================================

# Override LLM model name for any provider
# If not set, provider's default model will be used
# export BEEHIVE_LLM_MODEL="model-name"

# ============================================================================
# Google Cloud Authentication (if using Gemini or Firestore)
# ============================================================================

# Path to Google Cloud service account key file (JSON format)
# Only needed if not using Application Default Credentials (ADC)
# export GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account-key.json"

# Alternative: Use gcloud CLI authentication
# Run: gcloud auth application-default login

# ============================================================================
# Usage Examples
# ============================================================================

# 1. Fetch from all enabled sources (saves to Firestore):
#    beehive fetch

# 2. Fetch from sources with specific tags:
#    beehive fetch --tag threat-intel --tag url

# 3. Dry run (fetch but don't save to database):
#    beehive fetch --dry-run

# 4. Use custom config file:
#    beehive fetch --config /path/to/custom-config.toml

# 5. Filter by tag with dry run:
#    beehive fetch --tag vendor --dry-run

# 6. Specify Firestore database ID:
#    beehive fetch --firestore-database-id my-custom-db

# ============================================================================
# Command Line Flags (Override Environment Variables)
# ============================================================================

# --firestore-project-id     Google Cloud project ID for Firestore
# --firestore-database-id    Firestore database ID (optional)
# --llm-provider             LLM provider (gemini, openai, claude)
# --gemini-project           Google Cloud project ID for Gemini
# --gemini-location          Google Cloud location for Gemini
# --openai-api-key           OpenAI API key
# --claude-api-key           Claude API key
# --llm-model                LLM model name
# --config, -c               Path to sources configuration file
# --tag, -t                  Filter sources by tag (can be specified multiple times)
# --dry-run                  Dry run mode (fetch but don't save)

# ============================================================================
# Notes
# ============================================================================

# - The config file (BEEHIVE_CONFIG) should be in TOML format
# - See examples/config.example.toml for configuration file format
# - For Firestore storage, ensure you have proper GCP permissions:
#   - roles/datastore.user or roles/datastore.owner
# - For Gemini API, ensure Vertex AI API is enabled in your GCP project
# - LLM is used to extract IoCs from RSS feed articles
# - Feed sources (abuse.ch) don't require LLM as they provide structured data
# - Firestore database ID is optional; if not specified, uses the default database
# - You can create multiple Firestore databases in a project for different environments
